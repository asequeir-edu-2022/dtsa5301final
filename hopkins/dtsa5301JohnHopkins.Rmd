---
title: "COVID19 Data from John Hopkins"
author: "Antony Sequeira"
date: "2/9/2022"
output: pdf_document
---

# Following script installs the required libraries in Mac OSX
This section can be copied to a file or input into R console.  
You could also download it from my repo at https://github.com/asequeir-edu-2022/dtsa5301final

```
#!/usr/bin/env Rscript
r = getOption("repos")
r["CRAN"] = "http://cran.us.r-project.org"
options(repos = r)

print("Installing R libraries")
install.packages("chron")
install.packages("tidyverse")
install.packages("tinytex")

tinytex::install_tinytex()
```

# Overview
For fulfillment of DTSA-5301 finals *COVID19 dataset from the Johns Hopkins github site* part of the assignment.

# TODO explain data source
# TODO explain data
# TODO clean up data
# TODO create various ARDs
# TODO create plots (2)
# TODO model (1)
# TODO bias

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)
library(chron)
```
# Data source
The main data source is the github repository at
https://github.com/CSSEGISandData/COVID-19

We will use the data from the folder at  
https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series

Two of the time series tables are for the US confirmed cases and deaths, reported at the county level.  
They are `time_series_covid19_confirmed_US.csv` and `time_series_covid19_deaths_US.csv` respectively.

We will focus on analyzing the data for United States only.

These two files will provide our data for the analysis.

```{r load_data, echo=TRUE, results=FALSE, message=FALSE}
covid19_confirmed_url = "https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv"
covid19_deaths_url = "https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"

covid19_confirmed_raw <- read_csv(covid19_confirmed_url)
covid19_deaths_raw <- read_csv(covid19_deaths_url)
```


## Clean up data
We clean up the data mainly through the following three operations:  
- variables to factor for appropriate columns  
- date types from strings  
- remove unneeded columns  
- pivot

### Pivot long 

```{r pivot_data, echo=TRUE}
covid19_confirmed <- covid19_confirmed_raw %>%
  pivot_longer(cols = -c("UID", "iso2", "iso3", "code3", "FIPS", "Admin2",
                         "Province_State","Country_Region", "Lat", "Long_", "Combined_Key"),
                       names_to = "date",
                       values_to = "cases") %>%
  select(-c(Lat, Long_)) ## unwanted columns?

covid19_deaths <- covid19_deaths_raw %>%
  pivot_longer(cols = -c("UID", "iso2", "iso3", "code3", "FIPS", "Admin2",
                         "Province_State","Country_Region", "Lat", "Long_", "Combined_Key", "Population"),
                       names_to = "date",
                       values_to = "deaths") %>%
  select(-c(Lat, Long_)) ## unwanted columns?

```

### Join cases and deaths data and change column types (factor, date)


```{r join_factor_data, echo=TRUE}

covid19 <- covid19_confirmed %>%
  full_join(covid19_deaths) %>%
  mutate(iso3 = factor(iso3)) %>%
  mutate(Admin2 = factor(Admin2)) %>%
  mutate(Province_State = factor(Province_State)) %>%
  mutate(Country_Region = factor(Country_Region)) %>%
  mutate(date = mdy(date)) %>%
  # mutate(new_cases = cases - lag(cases)) %>%
  # mutate(new_deaths = deaths - lag(deaths)) %>%
  select (-c(UID, iso2, code3, FIPS))

# covid19 <- covid19 %>% filter(cases == 0)
```


## Missing data columns and plans to handle them
There is missing data in the following columns:
```{r missing_data, echo=TRUE}
names(which(colSums(is.na(covid19)) > 0))
# filter(covid19, is.na(Admin2))
```

I do not need cruise ships data for this report.
```{r cruise_ships_remove, echo=TRUE}
covid19 <- covid19 %>%
  filter(iso3 == "USA") %>%  # filter non states for simplicity
  filter(!is.na(Admin2))     # ignore cruise ships
```

### Summary of the cleaned up data

```{r summary, echo=TRUE}
summary(covid19)
```

### filter data
```{r filter_data, echo=TRUE}
covid19 <- covid19 %>%
  filter(cases > 0)
```

### Data issues
There are deaths with population zero. This is because the deaths are recorded with unassigned county (Alaska).

# EARLY EXIT
```{r summary_data, echo=TRUE}
knitr::knit_exit()
```



## Visualization and Analysis

### Generate necessary analysis ready data.  

Generate per state aggregated data.

```{r}
coovid19_by_state <- covid19 %>%
  group_by(Province_State, Country_Region, date) %>%
  summarise(cases = sum(cases), deaths = sum(deaths), Population = sum(Population)) %>%
  mutate(deaths_per_million = deaths * 1000000 / Population) %>%
  select(Province_State, Country_Region, date, 
         cases, deaths, deaths_per_million, Population) %>%
  ungroup()
```



```{r try1}
ny_data_sum <- ny_data %>%
  group_by(BORO, VIC_AGE_GROUP) %>% 
  mutate(BORO_BY_VIC_AGE = n()) %>%  # occurrences by victim age group by boro
  ungroup()  %>%
  group_by(month = lubridate::floor_date(OCCUR_DATE, "month")) %>%
  mutate(month_sum = sum(n())) %>% # occurrences by month
  ungroup() %>%
  group_by(month, BORO) %>%
  mutate(month_by_boro = sum(n())) %>%
  ungroup()
```

```{r sum2}
ny_data_sum2 <- ny_data %>%
  group_by(BORO, VIC_AGE_GROUP) %>% 
  summarize(BORO_BY_VAG = n(), .groups = 'drop') %>%
  ungroup()
```

```{r sum3}
ny_data_sum3 <- ny_data %>%
  group_by(month = lubridate::floor_date(OCCUR_DATE, "month")) %>%
  summarise(month_sum = sum(n())) %>% # occurrences by month
  ungroup()
```

## Visualizations
### Variations by the month of the year
We plot the total incidents by month.  
```{r plot1}
ny_data_sum3 %>%
ggplot(aes(x = month, y = month_sum)) +
geom_line(aes(color = "month")) +
geom_point(aes(color = "month")) +
geom_line(aes(y=month_sum, color = "month_sum")) +
geom_point(aes(y=month_sum, color = "month_sum")) +
labs(title = "Incidents in NY by month", y = NULL)
```
The above plot shows that the number of incidents vary seasonally.  
To see the 2020 peak more clearly, we plot a shorter time span.  
```{r plot2}
ny_data_sum3 %>%
  filter(year(month) > 2019) %>% 
  ggplot(aes(x = month, y = month_sum)) +
  geom_line(aes(color = "month")) +
  geom_point(aes(color = "month")) +
  geom_line(aes(y=month_sum, color = "month_sum")) +
  geom_point(aes(y=month_sum, color = "month_sum")) +
  labs(title = "Incidents in NY by month for years 2019 onwards", y = NULL)
```

This shows a clear peak in July of 2020.  

### Variations by borough
Generate the counts by borough.  
```{r plot4}
ny_data_sum %>%
  group_by(month_by_boro) %>%
  ggplot(aes(x=month, y=month_by_boro, group=BORO, color=BORO)) +
  geom_line() + 
  labs(title = "Incidents in NY by month by Boro", y = NULL)
```

Get a smaller time span to see a zoomed in view.  
```{r plot5}
ny_data_sum %>%
  filter(year(month) > 2015) %>% 
  filter(year(month) < 2019) %>%
  group_by(month_by_boro) %>%
  ggplot(aes(x=month, y=month_by_boro, group=BORO, color=BORO)) +
  geom_line() + 
  labs(title = "Plot fewer years to show peaks", y = NULL)
```

## Analysis
The plots show the following:  

- seasonal peaks mostly in summer
- higher levels of incidents based on the boro - Staten Island is lowest and Bronx and Brooklyn seem to be the higher end.
- the incidents show unusual higher numbers in first quarter of 2020


## Questions raised by the visualization and analysis (to be investigated)
- population of boros (Staten Island might have much smaller population) may be too different
- factors not in data such as income
- number of police officers per person

## Bias
There could be multiple sources of bias in the NY COVID19 data

- the data collection may be biased, it is possible that not all COVID19s are reported
- the standard race categories may not reflect the reality of the John Hopkins demographics

I have tried to focus on the boro and seasonality of the data to reduce bias.

## Modeling
```{r}
ny_data_doy <- ny_data_sum %>%
  filter(year(OCCUR_DATE)< 2020) %>% # avoiding covid years
  group_by(doy = yday(OCCUR_DATE)) %>%
  mutate(doy_sum = sum(n())) %>%
  ungroup()

mod <- lm(doy_sum ~ doy, data=ny_data_doy)
summary(mod)

ny_data_pred <-  ny_data_doy %>% mutate(doy_sum_pred = predict(mod))

ny_data_pred %>% ggplot() +
  geom_point(aes( x = doy, y = doy_sum), color = "blue") +
  # compare with predicted
  geom_point(aes( x = doy, y = doy_sum_pred), color = "red")

```


The plot clearly shows that the linear model does not fit the data of incidents given a day of the year.  
It looks like we need a different model (other than linear) to predict incidents given any day of the year. 

I hope to learn more about statistical modelling in future data science courses so I can model such data better.

## Session info
```{r, echo=FALSE}
sessionInfo()
```
